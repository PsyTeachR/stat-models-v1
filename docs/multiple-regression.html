<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Multiple regression | Learning Statistical Models Through Simulation in R</title>
  <meta name="description" content="Textbook on statistical models for social scientists." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Multiple regression | Learning Statistical Models Through Simulation in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Textbook on statistical models for social scientists." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Multiple regression | Learning Statistical Models Through Simulation in R" />
  
  <meta name="twitter:description" content="Textbook on statistical models for social scientists." />
  

<meta name="author" content="Dale J. Barr" />


<meta name="date" content="2021-05-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="understanding-correlation-and-regression-through-bivariate-simulation.html"/>
<link rel="next" href="interactions.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="include/psyteachr.css" type="text/css" />
<link rel="stylesheet" href="include/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-cite-this-book"><i class="fa fa-check"></i>How to cite this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#found-an-issue"><i class="fa fa-check"></i>Found an issue?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#information-for-educators"><i class="fa fa-check"></i>Information for educators</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#goal-of-this-course"><i class="fa fa-check"></i><b>1.1</b> Goal of this course</a><ul>
<li class="chapter" data-level="1.1.1" data-path="introduction.html"><a href="introduction.html#flexibility"><i class="fa fa-check"></i><b>1.1.1</b> Flexibility</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#generalizability"><i class="fa fa-check"></i><b>1.2</b> Generalizability</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#reproduciblity-and-transparency"><i class="fa fa-check"></i><b>1.3</b> Reproduciblity and Transparency</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#a-simulation-based-approach"><i class="fa fa-check"></i><b>1.4</b> A simulation-based approach</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#what-you-will-learn"><i class="fa fa-check"></i><b>1.5</b> What you will learn</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="understanding-correlation-and-regression-through-bivariate-simulation.html"><a href="understanding-correlation-and-regression-through-bivariate-simulation.html"><i class="fa fa-check"></i><b>2</b> Understanding correlation and regression through bivariate simulation</a><ul>
<li class="chapter" data-level="2.1" data-path="understanding-correlation-and-regression-through-bivariate-simulation.html"><a href="understanding-correlation-and-regression-through-bivariate-simulation.html#correlation-matrices"><i class="fa fa-check"></i><b>2.1</b> Correlation matrices</a></li>
<li class="chapter" data-level="2.2" data-path="understanding-correlation-and-regression-through-bivariate-simulation.html"><a href="understanding-correlation-and-regression-through-bivariate-simulation.html#simulating-bivariate-data"><i class="fa fa-check"></i><b>2.2</b> Simulating bivariate data</a><ul>
<li class="chapter" data-level="2.2.1" data-path="understanding-correlation-and-regression-through-bivariate-simulation.html"><a href="understanding-correlation-and-regression-through-bivariate-simulation.html#bivariate-app"><i class="fa fa-check"></i><b>2.2.1</b> Bivariate app</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="understanding-correlation-and-regression-through-bivariate-simulation.html"><a href="understanding-correlation-and-regression-through-bivariate-simulation.html#relationship-between-correlation-and-regression"><i class="fa fa-check"></i><b>2.3</b> Relationship between correlation and regression</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>3</b> Multiple regression</a><ul>
<li class="chapter" data-level="3.1" data-path="multiple-regression.html"><a href="multiple-regression.html#an-example-how-to-get-a-good-grade-in-statistics"><i class="fa fa-check"></i><b>3.1</b> An example: How to get a good grade in statistics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="multiple-regression.html"><a href="multiple-regression.html#data-import-and-visualization"><i class="fa fa-check"></i><b>3.1.1</b> Data import and visualization</a></li>
<li class="chapter" data-level="3.1.2" data-path="multiple-regression.html"><a href="multiple-regression.html#estimation-and-interpretation"><i class="fa fa-check"></i><b>3.1.2</b> Estimation and interpretation</a></li>
<li class="chapter" data-level="3.1.3" data-path="multiple-regression.html"><a href="multiple-regression.html#predictions-from-the-linear-model-using-predict"><i class="fa fa-check"></i><b>3.1.3</b> Predictions from the linear model using <code>predict()</code></a></li>
<li class="chapter" data-level="3.1.4" data-path="multiple-regression.html"><a href="multiple-regression.html#visualizing-partial-effects"><i class="fa fa-check"></i><b>3.1.4</b> Visualizing partial effects</a></li>
<li class="chapter" data-level="3.1.5" data-path="multiple-regression.html"><a href="multiple-regression.html#standardizing-coefficients"><i class="fa fa-check"></i><b>3.1.5</b> Standardizing coefficients</a></li>
<li class="chapter" data-level="3.1.6" data-path="multiple-regression.html"><a href="multiple-regression.html#model-comparison"><i class="fa fa-check"></i><b>3.1.6</b> Model comparison</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="multiple-regression.html"><a href="multiple-regression.html#dealing-with-categorical-predictors"><i class="fa fa-check"></i><b>3.2</b> Dealing with categorical predictors</a><ul>
<li class="chapter" data-level="3.2.1" data-path="multiple-regression.html"><a href="multiple-regression.html#dummy-coding"><i class="fa fa-check"></i><b>3.2.1</b> Dummy coding</a></li>
<li class="chapter" data-level="3.2.2" data-path="multiple-regression.html"><a href="multiple-regression.html#dummy-coding-when-k-2"><i class="fa fa-check"></i><b>3.2.2</b> Dummy coding when <span class="math inline">\(k &gt; 2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="multiple-regression.html"><a href="multiple-regression.html#equivalence-between-multiple-regression-and-one-way-anova"><i class="fa fa-check"></i><b>3.3</b> Equivalence between multiple regression and one-way ANOVA</a></li>
<li class="chapter" data-level="3.4" data-path="multiple-regression.html"><a href="multiple-regression.html#solution-to-partial-effect-plot"><i class="fa fa-check"></i><b>3.4</b> Solution to partial effect plot</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>4</b> Interactions</a><ul>
<li class="chapter" data-level="4.1" data-path="interactions.html"><a href="interactions.html#learning-objectives"><i class="fa fa-check"></i><b>4.1</b> Learning objectives</a></li>
<li class="chapter" data-level="4.2" data-path="interactions.html"><a href="interactions.html#interactions-1"><i class="fa fa-check"></i><b>4.2</b> Interactions</a></li>
<li class="chapter" data-level="4.3" data-path="interactions.html"><a href="interactions.html#cont-by-cat"><i class="fa fa-check"></i><b>4.3</b> Continuous-by-Categorical Interactions</a></li>
<li class="chapter" data-level="4.4" data-path="interactions.html"><a href="interactions.html#categorical-by-categorical-interactions"><i class="fa fa-check"></i><b>4.4</b> Categorical-by-Categorical Interactions</a><ul>
<li class="chapter" data-level="4.4.1" data-path="interactions.html"><a href="interactions.html#effects-of-cognitive-therapy-and-drug-therapy-on-mood"><i class="fa fa-check"></i><b>4.4.1</b> Effects of cognitive therapy and drug therapy on mood</a></li>
<li class="chapter" data-level="4.4.2" data-path="interactions.html"><a href="interactions.html#effects-in-a-factorial-design"><i class="fa fa-check"></i><b>4.4.2</b> Effects in a factorial design</a></li>
<li class="chapter" data-level="4.4.3" data-path="interactions.html"><a href="interactions.html#higher-order-designs"><i class="fa fa-check"></i><b>4.4.3</b> Higher-order designs</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="interactions.html"><a href="interactions.html#the-glm-for-a-factorial-design"><i class="fa fa-check"></i><b>4.5</b> The GLM for a factorial design</a><ul>
<li class="chapter" data-level="4.5.1" data-path="interactions.html"><a href="interactions.html#estimation-equations"><i class="fa fa-check"></i><b>4.5.1</b> Estimation equations</a></li>
<li class="chapter" data-level="4.5.2" data-path="interactions.html"><a href="interactions.html#factorial-app"><i class="fa fa-check"></i><b>4.5.2</b> Factorial App</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="interactions.html"><a href="interactions.html#code-your-own-categorical-predictors-in-factorial-designs"><i class="fa fa-check"></i><b>4.6</b> Code your own categorical predictors in factorial designs</a></li>
<li class="chapter" data-level="4.7" data-path="interactions.html"><a href="interactions.html#coding-schemes-for-categorical-variables"><i class="fa fa-check"></i><b>4.7</b> Coding schemes for categorical variables</a><ul>
<li class="chapter" data-level="4.7.1" data-path="interactions.html"><a href="interactions.html#simple-versus-main-effects"><i class="fa fa-check"></i><b>4.7.1</b> Simple versus main effects</a></li>
<li class="chapter" data-level="4.7.2" data-path="interactions.html"><a href="interactions.html#the-key-coding-schemes"><i class="fa fa-check"></i><b>4.7.2</b> The key coding schemes</a></li>
<li class="chapter" data-level="4.7.3" data-path="interactions.html"><a href="interactions.html#what-about-factors-with-more-than-two-levels"><i class="fa fa-check"></i><b>4.7.3</b> What about factors with more than two levels?</a></li>
<li class="chapter" data-level="4.7.4" data-path="interactions.html"><a href="interactions.html#example-three-level-factor"><i class="fa fa-check"></i><b>4.7.4</b> Example: Three-level factor</a></li>
<li class="chapter" data-level="4.7.5" data-path="interactions.html"><a href="interactions.html#how-to-create-your-own-numeric-predictors"><i class="fa fa-check"></i><b>4.7.5</b> How to create your own numeric predictors</a></li>
<li class="chapter" data-level="4.7.6" data-path="interactions.html"><a href="interactions.html#conclusion"><i class="fa fa-check"></i><b>4.7.6</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html"><i class="fa fa-check"></i><b>5</b> Introducing Linear Mixed-Effects Models</a><ul>
<li class="chapter" data-level="5.1" data-path="interactions.html"><a href="interactions.html#learning-objectives"><i class="fa fa-check"></i><b>5.1</b> Learning objectives</a></li>
<li class="chapter" data-level="5.2" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#modeling-multi-level-data"><i class="fa fa-check"></i><b>5.2</b> Modeling multi-level data</a></li>
<li class="chapter" data-level="5.3" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#how-to-model-these-data"><i class="fa fa-check"></i><b>5.3</b> How to model these data?</a><ul>
<li class="chapter" data-level="5.3.1" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#complete-pooling-one-size-fits-all"><i class="fa fa-check"></i><b>5.3.1</b> Complete pooling: One size fits all</a></li>
<li class="chapter" data-level="5.3.2" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#no-pooling"><i class="fa fa-check"></i><b>5.3.2</b> No pooling</a></li>
<li class="chapter" data-level="5.3.3" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#partial-pooling-using-mixed-effects-models"><i class="fa fa-check"></i><b>5.3.3</b> Partial pooling using mixed-effects models</a></li>
<li class="chapter" data-level="5.3.4" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#the-variance-covariance-matrix"><i class="fa fa-check"></i><b>5.3.4</b> The variance-covariance matrix</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#estimating-the-model-parameters"><i class="fa fa-check"></i><b>5.4</b> Estimating the model parameters</a></li>
<li class="chapter" data-level="5.5" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#interpreting-lmer-output-and-extracting-estimates"><i class="fa fa-check"></i><b>5.5</b> Interpreting <code>lmer()</code> output and extracting estimates</a><ul>
<li class="chapter" data-level="5.5.1" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#fixed-effects"><i class="fa fa-check"></i><b>5.5.1</b> Fixed effects</a></li>
<li class="chapter" data-level="5.5.2" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#random-effects"><i class="fa fa-check"></i><b>5.5.2</b> Random effects</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="introducing-linear-mixed-effects-models.html"><a href="introducing-linear-mixed-effects-models.html#multi-level-app"><i class="fa fa-check"></i><b>5.6</b> Multi-level app</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-mixed-effects-models-with-one-random-factor.html"><a href="linear-mixed-effects-models-with-one-random-factor.html"><i class="fa fa-check"></i><b>6</b> Linear mixed-effects models with one random factor</a><ul>
<li class="chapter" data-level="6.1" data-path="interactions.html"><a href="interactions.html#learning-objectives"><i class="fa fa-check"></i><b>6.1</b> Learning objectives</a></li>
<li class="chapter" data-level="6.2" data-path="linear-mixed-effects-models-with-one-random-factor.html"><a href="linear-mixed-effects-models-with-one-random-factor.html#when-and-why-would-you-want-to-replace-conventional-analyses-with-linear-mixed-effects-modeling"><i class="fa fa-check"></i><b>6.2</b> When, and why, would you want to replace conventional analyses with linear mixed-effects modeling?</a></li>
<li class="chapter" data-level="6.3" data-path="linear-mixed-effects-models-with-one-random-factor.html"><a href="linear-mixed-effects-models-with-one-random-factor.html#example-independent-samples-t-test-on-multi-level-data"><i class="fa fa-check"></i><b>6.3</b> Example: Independent-samples <span class="math inline">\(t\)</span>-test on multi-level data</a><ul>
<li class="chapter" data-level="6.3.1" data-path="linear-mixed-effects-models-with-one-random-factor.html"><a href="linear-mixed-effects-models-with-one-random-factor.html#when-is-a-random-intercepts-model-appropriate"><i class="fa fa-check"></i><b>6.3.1</b> When is a random-intercepts model appropriate?</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="linear-mixed-effects-models-with-one-random-factor.html"><a href="linear-mixed-effects-models-with-one-random-factor.html#expressing-the-study-design-and-performing-tests-in-regression"><i class="fa fa-check"></i><b>6.4</b> Expressing the study design and performing tests in regression</a><ul>
<li class="chapter" data-level="6.4.1" data-path="linear-mixed-effects-models-with-one-random-factor.html"><a href="linear-mixed-effects-models-with-one-random-factor.html#factors-with-more-than-two-levels"><i class="fa fa-check"></i><b>6.4.1</b> Factors with more than two levels</a></li>
<li class="chapter" data-level="6.4.2" data-path="linear-mixed-effects-models-with-one-random-factor.html"><a href="linear-mixed-effects-models-with-one-random-factor.html#multiparameter-tests"><i class="fa fa-check"></i><b>6.4.2</b> Multiparameter tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html"><i class="fa fa-check"></i><b>7</b> Linear mixed-effects models with crossed random factors</a><ul>
<li class="chapter" data-level="7.1" data-path="interactions.html"><a href="interactions.html#learning-objectives"><i class="fa fa-check"></i><b>7.1</b> Learning objectives</a></li>
<li class="chapter" data-level="7.2" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#web-app"><i class="fa fa-check"></i><b>7.2</b> Web app</a></li>
<li class="chapter" data-level="7.3" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#generalizing-over-encounters-between-subjects-and-stimuli"><i class="fa fa-check"></i><b>7.3</b> Generalizing over encounters between subjects and stimuli</a></li>
<li class="chapter" data-level="7.4" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#lme4-syntax-for-crossed-random-factors"><i class="fa fa-check"></i><b>7.4</b> lme4 syntax for crossed random factors</a></li>
<li class="chapter" data-level="7.5" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#specifying-random-effects"><i class="fa fa-check"></i><b>7.5</b> Specifying random effects</a><ul>
<li class="chapter" data-level="7.5.1" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#rules-for-choosing-random-effects-for-categorical-factors"><i class="fa fa-check"></i><b>7.5.1</b> Rules for choosing random effects for categorical factors</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#simulating-data-with-crossed-random-factors"><i class="fa fa-check"></i><b>7.6</b> Simulating data with crossed random factors</a><ul>
<li class="chapter" data-level="7.6.1" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#set-up-the-environment-and-define-the-parameters-for-the-dgp"><i class="fa fa-check"></i><b>7.6.1</b> Set up the environment and define the parameters for the DGP</a></li>
<li class="chapter" data-level="7.6.2" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#generate-a-sample-of-stimuli"><i class="fa fa-check"></i><b>7.6.2</b> Generate a sample of stimuli</a></li>
<li class="chapter" data-level="7.6.3" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#generate-a-sample-of-subjects"><i class="fa fa-check"></i><b>7.6.3</b> Generate a sample of subjects</a></li>
<li class="chapter" data-level="7.6.4" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#generate-a-sample-of-encounters-trials"><i class="fa fa-check"></i><b>7.6.4</b> Generate a sample of encounters (trials)</a></li>
<li class="chapter" data-level="7.6.5" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#join-subjects-items-and-trials"><i class="fa fa-check"></i><b>7.6.5</b> Join <code>subjects</code>, <code>items</code>, and <code>trials</code></a></li>
<li class="chapter" data-level="7.6.6" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#create-the-response-variable"><i class="fa fa-check"></i><b>7.6.6</b> Create the response variable</a></li>
<li class="chapter" data-level="7.6.7" data-path="linear-mixed-effects-models-with-crossed-random-factors.html"><a href="linear-mixed-effects-models-with-crossed-random-factors.html#fitting-the-model"><i class="fa fa-check"></i><b>7.6.7</b> Fitting the model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html"><i class="fa fa-check"></i><b>8</b> Generalized linear mixed-effects models</a><ul>
<li class="chapter" data-level="8.1" data-path="interactions.html"><a href="interactions.html#learning-objectives"><i class="fa fa-check"></i><b>8.1</b> Learning objectives</a></li>
<li class="chapter" data-level="8.2" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html#discrete-versus-continuous-data"><i class="fa fa-check"></i><b>8.2</b> Discrete versus continuous data</a><ul>
<li class="chapter" data-level="8.2.1" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html#why-not-model-discrete-data-as-continuous"><i class="fa fa-check"></i><b>8.2.1</b> Why not model discrete data as continuous?</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html#generalized-linear-models"><i class="fa fa-check"></i><b>8.3</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="8.4" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html#logistic-regression"><i class="fa fa-check"></i><b>8.4</b> Logistic regression</a><ul>
<li class="chapter" data-level="8.4.1" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html#terminology"><i class="fa fa-check"></i><b>8.4.1</b> Terminology</a></li>
<li class="chapter" data-level="8.4.2" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html#properties-of-log-odds"><i class="fa fa-check"></i><b>8.4.2</b> Properties of log odds</a></li>
<li class="chapter" data-level="8.4.3" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html#link-and-variance-functions"><i class="fa fa-check"></i><b>8.4.3</b> Link and variance functions</a></li>
<li class="chapter" data-level="8.4.4" data-path="generalized-linear-mixed-effects-models.html"><a href="generalized-linear-mixed-effects-models.html#estimating-logistic-regression-models-in-r"><i class="fa fa-check"></i><b>8.4.4</b> Estimating logistic regression models in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="modeling-ordinal-data.html"><a href="modeling-ordinal-data.html"><i class="fa fa-check"></i><b>9</b> Modeling Ordinal Data</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="symbols.html"><a href="symbols.html"><i class="fa fa-check"></i><b>A</b> Symbols</a><ul>
<li class="chapter" data-level="A.1" data-path="symbols.html"><a href="symbols.html#general-notes"><i class="fa fa-check"></i><b>A.1</b> General notes</a></li>
<li class="chapter" data-level="A.2" data-path="symbols.html"><a href="symbols.html#table-of-symbols"><i class="fa fa-check"></i><b>A.2</b> Table of symbols</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i><b>B</b> Bibliography</a></li>
<li class="divider"></li>
<li><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/" 
    target="blank"><img alt="Creative Commons License" 
    style="border-width:0" 
    src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></li>
<li><a href="https://psyteachr.github.io/books" target="blank">PsyTeachR Books</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Learning Statistical Models Through Simulation in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-regression" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Multiple regression</h1>
<p>General model for single-level data with <span class="math inline">\(m\)</span> predictors:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i
\]</span></p>
<p>The individual <span class="math inline">\(X_{hi}\)</span> variables can be any combination of continuous and/or categorical predictors, including interactions among variables.</p>
<p>The <span class="math inline">\(\beta\)</span> values are referred to as <strong>regression coefficients</strong>. Each <span class="math inline">\(\beta_h\)</span> is interpreted as the <strong>partial effect of <span class="math inline">\(\beta_h\)</span> holding constant all other predictor variables.</strong> If you have <span class="math inline">\(m\)</span> predictor variables, you have <span class="math inline">\(m+1\)</span> regression coefficients: one for the intercept, and one for each predictor.</p>
<p>Although discussions of multiple regression are common in statistical textbooks, you will rarely be able to apply the exact model above. This is because the above model assumes single-level data, whereas most psychological data is multi-level. However, the fundamentals are the same for both types of datasets, so it is worthwhile learning them for the simpler case first.</p>
<div id="an-example-how-to-get-a-good-grade-in-statistics" class="section level2">
<h2><span class="header-section-number">3.1</span> An example: How to get a good grade in statistics</h2>
<p>Let’s look at some (made up, but realistic) data to see how we can use multiple regression to answer various study questions. In this hypothetical study, you have a dataset for 100 statistics students, which includes their final course grade (<code>grade</code>), the number of lectures each student attended (<code>lecture</code>, an integer ranging from 0-10), how many times each student clicked to download online materials (<code>nclicks</code>) and each student’s grade point average prior to taking the course, <code>GPA</code>, which ranges from 0 (fail) to 4 (highest possible grade).</p>
<div id="data-import-and-visualization" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Data import and visualization</h3>
<p>Let’s load in the data <a href="data/grades.csv" target="_download">grades.csv</a> and have a look.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" title="1"><span class="kw">library</span>(<span class="st">&quot;corrr&quot;</span>) <span class="co"># correlation matrices</span></a>
<a class="sourceLine" id="cb46-2" title="2"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</a>
<a class="sourceLine" id="cb46-3" title="3"></a>
<a class="sourceLine" id="cb46-4" title="4">grades &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/grades.csv&quot;</span>, <span class="dt">col_types =</span> <span class="st">&quot;ddii&quot;</span>)</a>
<a class="sourceLine" id="cb46-5" title="5"></a>
<a class="sourceLine" id="cb46-6" title="6">grades</a></code></pre></div>
<pre><code>## # A tibble: 100 x 4
##    grade   GPA lecture nclicks
##    &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;
##  1  2.40 1.13        6      88
##  2  3.67 0.971       6      96
##  3  2.85 3.34        6     123
##  4  1.36 2.76        9      99
##  5  2.31 1.02        4      66
##  6  2.58 0.841       8      99
##  7  2.69 4           5      86
##  8  3.05 2.29        7     118
##  9  3.21 3.39        9      98
## 10  2.24 3.27       10     115
## # … with 90 more rows</code></pre>
<p>First let’s look at all the pairwise correlations.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" title="1">grades <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb48-2" title="2"><span class="st">  </span><span class="kw">correlate</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb48-3" title="3"><span class="st">  </span><span class="kw">shave</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb48-4" title="4"><span class="st">  </span><span class="kw">fashion</span>()</a></code></pre></div>
<pre><code>## 
## Correlation method: &#39;pearson&#39;
## Missing treated using: &#39;pairwise.complete.obs&#39;</code></pre>
<pre><code>##   rowname grade  GPA lecture nclicks
## 1   grade                           
## 2     GPA   .25                     
## 3 lecture   .24  .44                
## 4 nclicks   .16  .30     .36</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" title="1"><span class="kw">pairs</span>(grades)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pairs"></span>
<img src="03-multiple-regression_files/figure-html/pairs-1.png" alt="All pairwise relationships in the `grades` dataset." width="100%" />
<p class="caption">
Figure 2.2: All pairwise relationships in the <code>grades</code> dataset.
</p>
</div>
</div>
<div id="estimation-and-interpretation" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Estimation and interpretation</h3>
<p>To estimate the regression coefficients (the <span class="math inline">\(\beta\)</span>s), we will use the <code>lm()</code> function. For a GLM with <span class="math inline">\(m\)</span> predictors:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_m X_{mi} + e_i
\]</span></p>
<p>The call to base R’s <code>lm()</code> is</p>
<p><code>lm(Y ~ X1 + X2 + ... + Xm, data)</code></p>
<p>The <code>Y</code> variable is your response variable, and the <code>X</code> variables are the predictor variables. Note that you don’t need to explicitly specify the intercept or residual terms; those are included by default.</p>
<p>For the current data, let’s predict <code>grade</code> from <code>lecture</code> and <code>nclicks</code>.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" title="1">my_model &lt;-<span class="st"> </span><span class="kw">lm</span>(grade <span class="op">~</span><span class="st"> </span>lecture <span class="op">+</span><span class="st"> </span>nclicks, grades)</a>
<a class="sourceLine" id="cb52-2" title="2"></a>
<a class="sourceLine" id="cb52-3" title="3"><span class="kw">summary</span>(my_model)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = grade ~ lecture + nclicks, data = grades)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.21653 -0.40603  0.02267  0.60720  1.38558 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) 1.462037   0.571124   2.560   0.0120 *
## lecture     0.091501   0.045766   1.999   0.0484 *
## nclicks     0.005052   0.006051   0.835   0.4058  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8692 on 97 degrees of freedom
## Multiple R-squared:  0.06543,	Adjusted R-squared:  0.04616 
## F-statistic: 3.395 on 2 and 97 DF,  p-value: 0.03756</code></pre>
<p>We’ll often write the parameter symbol with a little hat on top to make clear that we are dealing with estimates from the sample rather than the (unknown) true population values. From above:</p>
<ul>
<li><span class="math inline">\(\hat{\beta}_0\)</span> = 1.46</li>
<li><span class="math inline">\(\hat{\beta}_1\)</span> = 0.09</li>
<li><span class="math inline">\(\hat{\beta}_2\)</span> = 0.01</li>
</ul>
<p>This tells us that a person’s predicted grade is related to their lecture attendance and download rate by the following formula:</p>
<p><code>grade</code> = 1.46 + 0.09 <span class="math inline">\(\times\)</span> <code>lecture</code> + 0.01 <span class="math inline">\(\times\)</span> <code>nclicks</code></p>
<p>Because <span class="math inline">\(\hat{\beta}_1\)</span> and <span class="math inline">\(\hat{\beta}_2\)</span> are both positive, we know that higher values of <code>lecture</code> and <code>nclicks</code> are associated with higher grades.</p>
<p>So if you were asked, what grade would you predict for a student who attends 3 lectures and downloaded 70 times, you could easily figure that out by substituting the appropriate values.</p>
<p><code>grade</code> = 1.46 + 0.09 <span class="math inline">\(\times\)</span> 3 + 0.01 <span class="math inline">\(\times\)</span> 70</p>
<p>which equals</p>
<p><code>grade</code> = 1.46 + 0.27 + 0.7</p>
<p>and reduces to</p>
<p><code>grade</code> = 2.43</p>
</div>
<div id="predictions-from-the-linear-model-using-predict" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Predictions from the linear model using <code>predict()</code></h3>
<p>If we want to predict response values for new predictor values, we can use the <code>predict()</code> function in base R.</p>
<p><code>predict()</code> takes two main arguments. The first argument is a fitted model object (i.e., <code>my_model</code> from above) and the second is a data frame (or tibble) containing new values for the predictors.</p>
<div class="warning">
<p>
You need to include <strong>all</strong> of the predictor variables in the new table. You’ll get an error message if your tibble is missing any predictors. You also need to make sure that the variable names in the new table <strong>exactly</strong> match the variable names in the model.
</p>
</div>
<p>Let’s create a tibble with new values and try it out.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" title="1"><span class="co">## a &#39;tribble&#39; is a way to make a tibble by rows,</span></a>
<a class="sourceLine" id="cb54-2" title="2"><span class="co">## rather than by columns. This is sometimes useful</span></a>
<a class="sourceLine" id="cb54-3" title="3">new_data &lt;-<span class="st"> </span><span class="kw">tribble</span>(<span class="op">~</span>lecture, <span class="op">~</span>nclicks,</a>
<a class="sourceLine" id="cb54-4" title="4">                    <span class="dv">3</span>, <span class="dv">70</span>,</a>
<a class="sourceLine" id="cb54-5" title="5">                    <span class="dv">10</span>, <span class="dv">130</span>,</a>
<a class="sourceLine" id="cb54-6" title="6">                    <span class="dv">0</span>, <span class="dv">20</span>,</a>
<a class="sourceLine" id="cb54-7" title="7">                    <span class="dv">5</span>, <span class="dv">100</span>)</a></code></pre></div>
<div class="info">
<p>The <code>tribble()</code> function provides a way to build a tibble row by row, whereas with <code>tibble()</code> the table is built column by column.</p>
<p>The first row of the <code>tribble()</code> contains the column names, each preceded by a tilde (<code>~</code>).</p>
<p>This is sometimes easier to read than doing it row by row, although the result is the same. Consider that we could have made the above table using</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" title="1">new_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">lecture =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb55-2" title="2">                   <span class="dt">nclicks =</span> <span class="kw">c</span>(<span class="dv">70</span>, <span class="dv">130</span>, <span class="dv">20</span>, <span class="dv">100</span>))</a></code></pre></div>
</div>
<p>Now that we’ve created our table <code>new_data</code>, we just pass it to <code>predict()</code> and it will return a vector with the predictions for <span class="math inline">\(Y\)</span> (<code>grade</code>).</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" title="1"><span class="kw">predict</span>(my_model, new_data)</a></code></pre></div>
<pre><code>##        1        2        3        4 
## 2.090214 3.033869 1.563087 2.424790</code></pre>
<p>That’s great, but maybe we want to line it up with the predictor values. We can do this by just adding it as a new column to <code>new_data</code>.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" title="1">new_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb58-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predicted_grade =</span> <span class="kw">predict</span>(my_model, new_data))</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   lecture nclicks predicted_grade
##     &lt;dbl&gt;   &lt;dbl&gt;           &lt;dbl&gt;
## 1       3      70            2.09
## 2      10     130            3.03
## 3       0      20            1.56
## 4       5     100            2.42</code></pre>
<p>Want to see more options for <code>predict()</code>? Check the help at <code>?predict.lm</code>.</p>
</div>
<div id="visualizing-partial-effects" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Visualizing partial effects</h3>
<p>As noted above the parameter estimates for each regression coefficient tell us about the <strong>partial</strong> effect of that variable; it’s effect holding all of the others constant. Is there a way to visualize this partial effect? Yes, you can do this using the <code>predict()</code> function, by making a table with varying values for the focal predictor, while filling in all of the other predictors with their mean values.</p>
<p>For example, let’s visualize the partial effect of <code>lecture</code> on <code>grade</code> holding <code>nclicks</code> constant at its mean value.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" title="1">nclicks_mean &lt;-<span class="st"> </span>grades <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(nclicks) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mean</span>()</a>
<a class="sourceLine" id="cb60-2" title="2"></a>
<a class="sourceLine" id="cb60-3" title="3"><span class="co">## new data for prediction</span></a>
<a class="sourceLine" id="cb60-4" title="4">new_lecture &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">lecture =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">10</span>,</a>
<a class="sourceLine" id="cb60-5" title="5">                      <span class="dt">nclicks =</span> nclicks_mean)</a>
<a class="sourceLine" id="cb60-6" title="6"></a>
<a class="sourceLine" id="cb60-7" title="7"><span class="co">## add the predicted value to new_lecture</span></a>
<a class="sourceLine" id="cb60-8" title="8">new_lecture2 &lt;-<span class="st"> </span>new_lecture <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb60-9" title="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">grade =</span> <span class="kw">predict</span>(my_model, new_lecture))</a>
<a class="sourceLine" id="cb60-10" title="10"></a>
<a class="sourceLine" id="cb60-11" title="11">new_lecture2</a></code></pre></div>
<pre><code>## # A tibble: 11 x 3
##    lecture nclicks grade
##      &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;
##  1       0    98.3  1.96
##  2       1    98.3  2.05
##  3       2    98.3  2.14
##  4       3    98.3  2.23
##  5       4    98.3  2.32
##  6       5    98.3  2.42
##  7       6    98.3  2.51
##  8       7    98.3  2.60
##  9       8    98.3  2.69
## 10       9    98.3  2.78
## 11      10    98.3  2.87</code></pre>
<p>Now let’s plot.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" title="1"><span class="kw">ggplot</span>(grades, <span class="kw">aes</span>(lecture, grade)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb62-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb62-3" title="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> new_lecture2)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:partial-lecture-plot"></span>
<img src="03-multiple-regression_files/figure-html/partial-lecture-plot-1.png" alt="Partial effect of 'lecture' on grade, with nclicks at its mean value." width="100%" />
<p class="caption">
Figure 3.1: Partial effect of ‘lecture’ on grade, with nclicks at its mean value.
</p>
</div>
<div class="warning">
<p>Partial effect plots only make sense when there are no interactions in the model between the focal predictor and any other predictor.</p>
<p>The reason is that when there are interactions, the partial effect of focal predictor <span class="math inline">\(X_i\)</span> will differ across the values of the other variables it interacts with.</p>
</div>
<p>Now can you visualize the partial effect of <code>nclicks</code> on <code>grade</code>?</p>
<p>See the solution at the bottom of the page.</p>
</div>
<div id="standardizing-coefficients" class="section level3">
<h3><span class="header-section-number">3.1.5</span> Standardizing coefficients</h3>
<p>One kind of question that we often use multiple regression to address is, <strong>Which predictors matter most in predicting Y?</strong></p>
<p>Now, you can’t just read off the <span class="math inline">\(\hat{\beta}\)</span> values and choose the one with the largest absolute value, because the predictors are all on different scales. To answer this question, you need to <strong>center</strong> and <strong>scale</strong> the predictors.</p>
<p>Remember <span class="math inline">\(z\)</span> scores?</p>
<p><span class="math display">\[
z = \frac{X - \mu_x}{\sigma_x}
\]</span></p>
<p>A <span class="math inline">\(z\)</span> score represents the distance of a score <span class="math inline">\(X\)</span> from the sample mean (<span class="math inline">\(\mu_x\)</span>) in standard deviation units (<span class="math inline">\(\sigma_x\)</span>). So a <span class="math inline">\(z\)</span> score of 1 means that the score is one standard deviation about the mean; a <span class="math inline">\(z\)</span>-score of -2.5 means 2.5 standard deviations below the mean. <span class="math inline">\(Z\)</span>-scores give us a way of comparing things that come from different populations by calibrating them to the standard normal distribution (a distribution with a mean of 0 and a standard deviation of 1).</p>
<p>So we re-scale our predictors by converting them to <span class="math inline">\(z\)</span>-scores. This is easy enough to do.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb63-1" title="1">grades2 &lt;-<span class="st"> </span>grades <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb63-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">lecture_c =</span> (lecture <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(lecture)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(lecture),</a>
<a class="sourceLine" id="cb63-3" title="3">         <span class="dt">nclicks_c =</span> (nclicks <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(nclicks)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(nclicks))</a>
<a class="sourceLine" id="cb63-4" title="4"></a>
<a class="sourceLine" id="cb63-5" title="5">grades2</a></code></pre></div>
<pre><code>## # A tibble: 100 x 6
##    grade   GPA lecture nclicks lecture_c nclicks_c
##    &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1  2.40 1.13        6      88  -0.484     -0.666 
##  2  3.67 0.971       6      96  -0.484     -0.150 
##  3  2.85 3.34        6     123  -0.484      1.59  
##  4  1.36 2.76        9      99   0.982      0.0439
##  5  2.31 1.02        4      66  -1.46      -2.09  
##  6  2.58 0.841       8      99   0.493      0.0439
##  7  2.69 4           5      86  -0.972     -0.796 
##  8  3.05 2.29        7     118   0.00488    1.27  
##  9  3.21 3.39        9      98   0.982     -0.0207
## 10  2.24 3.27       10     115   1.47       1.08  
## # … with 90 more rows</code></pre>
<p>Now let’s re-fit the model using the centered and scaled predictors.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" title="1">my_model_scaled &lt;-<span class="st"> </span><span class="kw">lm</span>(grade <span class="op">~</span><span class="st"> </span>lecture_c <span class="op">+</span><span class="st"> </span>nclicks_c, grades2)</a>
<a class="sourceLine" id="cb65-2" title="2"></a>
<a class="sourceLine" id="cb65-3" title="3"><span class="kw">summary</span>(my_model_scaled)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = grade ~ lecture_c + nclicks_c, data = grades2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.21653 -0.40603  0.02267  0.60720  1.38558 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.59839    0.08692  29.895   &lt;2e-16 ***
## lecture_c    0.18734    0.09370   1.999   0.0484 *  
## nclicks_c    0.07823    0.09370   0.835   0.4058    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8692 on 97 degrees of freedom
## Multiple R-squared:  0.06543,	Adjusted R-squared:  0.04616 
## F-statistic: 3.395 on 2 and 97 DF,  p-value: 0.03756</code></pre>
<p>This tells us that lecture_c has a relatively larger influence; for each standard deviation increase in this variable, <code>grade</code> increases by about 0.19.</p>
</div>
<div id="model-comparison" class="section level3">
<h3><span class="header-section-number">3.1.6</span> Model comparison</h3>
<p>Another common kind of question multiple regression is also used to address is of the form: Does some predictor or set of predictors of interest significantly impact my response variable <strong>over and above the effects of some control variables</strong>?</p>
<p>For example, we saw above that the model including <code>lecture</code> and <code>nclicks</code> was statistically significant,
<span class="math inline">\(F(2, 97) = 3.395\)</span>,
<span class="math inline">\(p = 0.038\)</span>.</p>
<p>The null hypothesis for a regression model with <span class="math inline">\(m\)</span> predictors is</p>
<p><span class="math display">\[H_0: \beta_1 = \beta_2 = \ldots = \beta_m = 0;\]</span></p>
<p>in other words, that all of the coefficients (except the intercept) are zero. If the null hypothesis is true, then the null model</p>
<p><span class="math display">\[Y_i = \beta_0\]</span></p>
<p>gives just as good of a prediction as the model including all of the predictors and their coefficients. In other words, your best prediction for <span class="math inline">\(Y\)</span> is just its mean (<span class="math inline">\(\mu_y\)</span>); the <span class="math inline">\(X\)</span> variables are irrelevant. We rejected this null hypothesis, which implies that we can do better by including our two predictors, <code>lecture</code> and <code>nclicks</code>.</p>
<p>But you might ask: maybe its the case that better students get better grades, and the relationship between <code>lecture</code>, <code>nclicks</code>, and <code>grade</code> is just mediated by student quality. After all, better students are more likely to go to lecture and download the materials. So we can ask, are attendance and downloads associated with better grades <strong>above and beyond</strong> student ability, as measured by GPA?</p>
<p>The way we can test this hypothesis is by using <strong>model comparison</strong>. The logic is as follows. First, estimate a model containing any control predictors but excluding the focal predictors of interest. Second, estimate a model containing the control predictors as well as the focal predictors. Finally, compare the two models, to see if there is any statistically significant gain by including the predictors.</p>
<p>Here is how you do this:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" title="1">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(grade <span class="op">~</span><span class="st"> </span>GPA, grades) <span class="co"># control model</span></a>
<a class="sourceLine" id="cb67-2" title="2">m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(grade <span class="op">~</span><span class="st"> </span>GPA <span class="op">+</span><span class="st"> </span>lecture <span class="op">+</span><span class="st"> </span>nclicks, grades) <span class="co"># bigger model</span></a>
<a class="sourceLine" id="cb67-3" title="3"></a>
<a class="sourceLine" id="cb67-4" title="4"><span class="kw">anova</span>(m1, m2)</a></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: grade ~ GPA
## Model 2: grade ~ GPA + lecture + nclicks
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     98 73.528                           
## 2     96 71.578  2    1.9499 1.3076 0.2752</code></pre>
<p>The null hypothesis is that we are just as good predicting <code>grade</code> from <code>GPA</code> as we are predicting it from <code>GPA</code> plus <code>lecture</code> and <code>nclicks</code>. We will reject the null if adding these two variables leads to a substantial enough reduction in the <strong>residual sums of squares</strong> (RSS); i.e., if they explain away enough residual variance.</p>
<p>We see that this is not the case:
<span class="math inline">\(F(2, 96 ) = 1.308\)</span>,
<span class="math inline">\(p = 0.275\)</span>. So we don’t have evidence that lecture attendance and downloading the online materials is associated with better grades above and beyond student ability, as measured by GPA.</p>
</div>
</div>
<div id="dealing-with-categorical-predictors" class="section level2">
<h2><span class="header-section-number">3.2</span> Dealing with categorical predictors</h2>
<p>You can include categorical predictors in a regression model, but first you have to code them as numerical variables. There are a couple of important considerations here.</p>
<div type="danger">
<p>A <strong>nominal</strong> variable is a categorical variable for which there is no inherent ordering among the levels of the variable. Pet ownership (cat, dog, ferret) is a nominal variable; cat is not greater than dog and dog is not greater than ferret.</p>
<p>It is common to code nominal variables using numbers. However, you have to be <strong>very careful</strong> about using numerically-coded nominal variables in your models. If you have a number that is really just a nominal variable, make sure you define it as type <code>factor()</code> before entering it into the model. Otherwise, it will try to treat it as an actual number, and the results of your modeling will be garbage!</p>
<p>It is far too easy to make this mistake, and difficult to catch if authors do not share their data and code. In 2016, <a href="https://www.sciencedirect.com/science/article/pii/S0960982216306704">a paper on religious affiliation and altruism in children that was published in Current Biology had to be retracted for just this kind of mistake</a>.</p>
</div>
<div id="dummy-coding" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Dummy coding</h3>
<p>For a factor with two levels, choose one level as zero and the other as one. The choice is arbitrary, and will affect the sign of the coefficient, but not its standard error or p-value. Here is some code that will do this. Note that if you have a predictor of type character or factor, R will automatically do that for you. We don’t want R to do this for reasons that will become apparent in the next lecture, so let’s learn how to make our own numeric predictor.</p>
<p>First, we gin up some fake data to use in our analysis.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" title="1">fake_data &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">Y =</span> <span class="kw">rnorm</span>(<span class="dv">10</span>),</a>
<a class="sourceLine" id="cb69-2" title="2">                    <span class="dt">group =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>), <span class="dt">each =</span> <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb69-3" title="3"></a>
<a class="sourceLine" id="cb69-4" title="4">fake_data</a></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##          Y group
##      &lt;dbl&gt; &lt;chr&gt;
##  1 -1.62   A    
##  2  0.418  A    
##  3  0.401  A    
##  4 -0.744  A    
##  5 -0.723  A    
##  6 -0.284  B    
##  7  0.751  B    
##  8 -0.0766 B    
##  9  0.380  B    
## 10  0.792  B</code></pre>
<p>Now let’s add a new variable, <code>group_d</code>, which is the dummy coded group variable. We will use the <code>dplyr::if_else()</code> function to define the new column.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" title="1">fake_data2 &lt;-<span class="st"> </span>fake_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb71-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">group_d =</span> <span class="kw">if_else</span>(group <span class="op">==</span><span class="st"> &quot;B&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb71-3" title="3"></a>
<a class="sourceLine" id="cb71-4" title="4">fake_data2</a></code></pre></div>
<pre><code>## # A tibble: 10 x 3
##          Y group group_d
##      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;
##  1 -1.62   A           0
##  2  0.418  A           0
##  3  0.401  A           0
##  4 -0.744  A           0
##  5 -0.723  A           0
##  6 -0.284  B           1
##  7  0.751  B           1
##  8 -0.0766 B           1
##  9  0.380  B           1
## 10  0.792  B           1</code></pre>
<p>Now we just run it as a regular regression model.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>group_d, fake_data2))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ group_d, data = fake_data2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.1631 -0.3646 -0.1016  0.4692  0.8710 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  -0.4526     0.3135  -1.444    0.187
## group_d       0.7650     0.4434   1.726    0.123
## 
## Residual standard error: 0.701 on 8 degrees of freedom
## Multiple R-squared:  0.2712,	Adjusted R-squared:  0.1801 
## F-statistic: 2.978 on 1 and 8 DF,  p-value: 0.1227</code></pre>
<p>Note that if we reverse the coding we get the same result, just the sign is different.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" title="1">fake_data3 &lt;-<span class="st"> </span>fake_data <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb75-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">group_d =</span> <span class="kw">if_else</span>(group <span class="op">==</span><span class="st"> &quot;A&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb75-3" title="3"></a>
<a class="sourceLine" id="cb75-4" title="4"><span class="kw">summary</span>(<span class="kw">lm</span>(Y <span class="op">~</span><span class="st"> </span>group_d, fake_data3))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ group_d, data = fake_data3)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.1631 -0.3646 -0.1016  0.4692  0.8710 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.3125     0.3135   0.997    0.348
## group_d      -0.7650     0.4434  -1.726    0.123
## 
## Residual standard error: 0.701 on 8 degrees of freedom
## Multiple R-squared:  0.2712,	Adjusted R-squared:  0.1801 
## F-statistic: 2.978 on 1 and 8 DF,  p-value: 0.1227</code></pre>
<p>The interpretation of the intercept is the estimated mean for the group coded as zero. You can see by plugging in zero for X in the prediction formula below. Thus, <span class="math inline">\(\beta_1\)</span> can be interpreted as the difference between the mean for the baseline group and the group coded as 1.</p>
<p><span class="math display">\[\hat{Y_i} = \hat{\beta}_0 + \hat{\beta}_1 X_i \]</span></p>
<!--
<div type="info">

Why not just use **factors** as your predictors?

</div>
-->
</div>
<div id="dummy-coding-when-k-2" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Dummy coding when <span class="math inline">\(k &gt; 2\)</span></h3>
<p>When the predictor variable is a factor with <span class="math inline">\(k\)</span> levels where <span class="math inline">\(k&gt;2\)</span>, we need <span class="math inline">\(k-1\)</span> predictors to code that variable. So if the factor has 4 levels, we’ll need to define three predictors. Here is code to do that. Try it out and see if you can figure out how it works.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" title="1">mydata &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">season =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;winter&quot;</span>, <span class="st">&quot;spring&quot;</span>, <span class="st">&quot;summer&quot;</span>, <span class="st">&quot;fall&quot;</span>), <span class="dt">each =</span> <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb77-2" title="2">                 <span class="dt">bodyweight_kg =</span> <span class="kw">c</span>(<span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dv">105</span>, <span class="dv">3</span>),</a>
<a class="sourceLine" id="cb77-3" title="3">                                   <span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dv">103</span>, <span class="dv">3</span>),</a>
<a class="sourceLine" id="cb77-4" title="4">                                   <span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="dv">101</span>, <span class="dv">3</span>),</a>
<a class="sourceLine" id="cb77-5" title="5">                                   <span class="kw">rnorm</span>(<span class="dv">5</span>, <span class="fl">102.5</span>, <span class="dv">3</span>)))</a>
<a class="sourceLine" id="cb77-6" title="6"></a>
<a class="sourceLine" id="cb77-7" title="7">mydata</a></code></pre></div>
<pre><code>## # A tibble: 20 x 2
##    season bodyweight_kg
##    &lt;chr&gt;          &lt;dbl&gt;
##  1 winter         112. 
##  2 winter         108. 
##  3 winter         101. 
##  4 winter         111. 
##  5 winter         107. 
##  6 spring          99.9
##  7 spring         102. 
##  8 spring         105. 
##  9 spring         102. 
## 10 spring         100. 
## 11 summer         105. 
## 12 summer         103. 
## 13 summer         101. 
## 14 summer         105. 
## 15 summer          98.7
## 16 fall           105. 
## 17 fall           103. 
## 18 fall           107. 
## 19 fall           101. 
## 20 fall           104.</code></pre>
<p>Now let’s add three predictors to code the variable <code>season</code>.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" title="1"><span class="co">## baseline value is &#39;winter&#39;</span></a>
<a class="sourceLine" id="cb79-2" title="2">mydata2 &lt;-<span class="st"> </span>mydata <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb79-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">V1 =</span> <span class="kw">if_else</span>(season <span class="op">==</span><span class="st"> &quot;spring&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb79-4" title="4">         <span class="dt">V2 =</span> <span class="kw">if_else</span>(season <span class="op">==</span><span class="st"> &quot;summer&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>),</a>
<a class="sourceLine" id="cb79-5" title="5">         <span class="dt">V3 =</span> <span class="kw">if_else</span>(season <span class="op">==</span><span class="st"> &quot;fall&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb79-6" title="6"></a>
<a class="sourceLine" id="cb79-7" title="7">mydata2</a></code></pre></div>
<pre><code>## # A tibble: 20 x 5
##    season bodyweight_kg    V1    V2    V3
##    &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 winter         112.      0     0     0
##  2 winter         108.      0     0     0
##  3 winter         101.      0     0     0
##  4 winter         111.      0     0     0
##  5 winter         107.      0     0     0
##  6 spring          99.9     1     0     0
##  7 spring         102.      1     0     0
##  8 spring         105.      1     0     0
##  9 spring         102.      1     0     0
## 10 spring         100.      1     0     0
## 11 summer         105.      0     1     0
## 12 summer         103.      0     1     0
## 13 summer         101.      0     1     0
## 14 summer         105.      0     1     0
## 15 summer          98.7     0     1     0
## 16 fall           105.      0     0     1
## 17 fall           103.      0     0     1
## 18 fall           107.      0     0     1
## 19 fall           101.      0     0     1
## 20 fall           104.      0     0     1</code></pre>
</div>
</div>
<div id="equivalence-between-multiple-regression-and-one-way-anova" class="section level2">
<h2><span class="header-section-number">3.3</span> Equivalence between multiple regression and one-way ANOVA</h2>
<p>If we wanted to see whether our bodyweight varies over season, we could do a one way ANOVA on <code>mydata2</code> like so.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" title="1"><span class="co">## make season into a factor with baseline level &#39;winter&#39;</span></a>
<a class="sourceLine" id="cb81-2" title="2">mydata3 &lt;-<span class="st"> </span>mydata2 <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb81-3" title="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">season =</span> <span class="kw">factor</span>(season, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;winter&quot;</span>, <span class="st">&quot;spring&quot;</span>, <span class="st">&quot;summer&quot;</span>, <span class="st">&quot;fall&quot;</span>)))</a>
<a class="sourceLine" id="cb81-4" title="4"></a>
<a class="sourceLine" id="cb81-5" title="5">my_anova &lt;-<span class="st"> </span><span class="kw">aov</span>(bodyweight_kg <span class="op">~</span><span class="st"> </span>season, mydata3)</a>
<a class="sourceLine" id="cb81-6" title="6"><span class="kw">summary</span>(my_anova)</a></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## season       3  109.7   36.55   4.051 0.0255 *
## Residuals   16  144.3    9.02                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>OK, now can we replicate that result using the regression model below?</p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i} + e_i\]</span></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" title="1"><span class="kw">summary</span>(<span class="kw">lm</span>(bodyweight_kg <span class="op">~</span><span class="st"> </span>V1 <span class="op">+</span><span class="st"> </span>V2 <span class="op">+</span><span class="st"> </span>V3, mydata3))</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = bodyweight_kg ~ V1 + V2 + V3, data = mydata3)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9786 -1.5333  0.0761  2.4149  4.5209 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  107.756      1.343  80.218  &lt; 2e-16 ***
## V1            -6.078      1.900  -3.199  0.00559 ** 
## V2            -5.314      1.900  -2.797  0.01291 *  
## V3            -3.917      1.900  -2.062  0.05585 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.004 on 16 degrees of freedom
## Multiple R-squared:  0.4317,	Adjusted R-squared:  0.3251 
## F-statistic: 4.051 on 3 and 16 DF,  p-value: 0.02551</code></pre>
<p>Note that the <span class="math inline">\(F\)</span> values and <span class="math inline">\(p\)</span> values are identical for the two methods!</p>
</div>
<div id="solution-to-partial-effect-plot" class="section level2">
<h2><span class="header-section-number">3.4</span> Solution to partial effect plot</h2>
<p>First create a tibble with new predictors. We might also want to know the range of values that <code>nclicks</code> varies over.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" title="1">lecture_mean &lt;-<span class="st"> </span>grades <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(lecture) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mean</span>()</a>
<a class="sourceLine" id="cb85-2" title="2">min_nclicks &lt;-<span class="st"> </span>grades <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(nclicks) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">min</span>()</a>
<a class="sourceLine" id="cb85-3" title="3">max_nclicks &lt;-<span class="st"> </span>grades <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(nclicks) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">max</span>()</a>
<a class="sourceLine" id="cb85-4" title="4"></a>
<a class="sourceLine" id="cb85-5" title="5"><span class="co">## new data for prediction</span></a>
<a class="sourceLine" id="cb85-6" title="6">new_nclicks &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">lecture =</span> lecture_mean,</a>
<a class="sourceLine" id="cb85-7" title="7">                      <span class="dt">nclicks =</span> min_nclicks<span class="op">:</span>max_nclicks)</a>
<a class="sourceLine" id="cb85-8" title="8"></a>
<a class="sourceLine" id="cb85-9" title="9"><span class="co">## add the predicted value to new_lecture</span></a>
<a class="sourceLine" id="cb85-10" title="10">new_nclicks2 &lt;-<span class="st"> </span>new_nclicks <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb85-11" title="11"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">grade =</span> <span class="kw">predict</span>(my_model, new_nclicks))</a>
<a class="sourceLine" id="cb85-12" title="12"></a>
<a class="sourceLine" id="cb85-13" title="13">new_nclicks2</a></code></pre></div>
<pre><code>## # A tibble: 76 x 3
##    lecture nclicks grade
##      &lt;dbl&gt;   &lt;int&gt; &lt;dbl&gt;
##  1    6.99      54  2.37
##  2    6.99      55  2.38
##  3    6.99      56  2.38
##  4    6.99      57  2.39
##  5    6.99      58  2.39
##  6    6.99      59  2.40
##  7    6.99      60  2.40
##  8    6.99      61  2.41
##  9    6.99      62  2.41
## 10    6.99      63  2.42
## # … with 66 more rows</code></pre>
<p>Now plot.</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" title="1"><span class="kw">ggplot</span>(grades, <span class="kw">aes</span>(nclicks, grade)) <span class="op">+</span></a>
<a class="sourceLine" id="cb87-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb87-3" title="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> new_nclicks2)</a></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:partial-nclicks"></span>
<img src="03-multiple-regression_files/figure-html/partial-nclicks-1.png" alt="Partial effect plot of nclicks on grade." width="100%" />
<p class="caption">
Figure 3.2: Partial effect plot of nclicks on grade.
</p>
</div>

</div>
</div>
<div class="psyteachr_footer">
  
</div>
<script>

/* update total correct if #total_correct exists */
update_total_correct = function() {
  if (t = document.getElementById("total_correct")) {
    t.innerHTML =
      document.getElementsByClassName("correct").length + " of " +
      document.getElementsByClassName("solveme").length + " correct";
  }
}

/* solution button toggling function */
b_func = function() {
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "");
  }
  
  if (my_answer !== "" & real_answers.includes(my_answer)) {
    cl.add("correct");
  } else {
    cl.remove("correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol){
    var tol = JSON.parse(this.dataset.tol);  
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("correct");
    } else {
      cl.remove("correct");
    }  
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("correct");
    }  
  }
  
  update_total_correct();
}

window.onload = function() {
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('solution')) {
      buttons[i].onclick = b_func;
    }
  }
  
  /* set up solveme inputs */
  var solveme = document.getElementsByClassName("solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off"); 
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";
    
    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;
    
    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  update_total_correct();
}

</script>
            </section>

          </div>
        </div>
      </div>
<a href="understanding-correlation-and-regression-through-bivariate-simulation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interactions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"],
"google": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
