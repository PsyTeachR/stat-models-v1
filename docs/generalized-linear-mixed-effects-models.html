<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 8 Generalized linear mixed-effects models | Learning Statistical Models Through Simulation in R</title>
<meta name="author" content="Dale J. Barr">
<meta name="description" content="This chapter is under construction as of October 14, 2021; contents may change!  8.1 Learning objectives distinguish discrete from continuous data estimate logit models  8.2 Discrete versus...">
<meta name="generator" content="bookdown 0.23 with bs4_book()">
<meta property="og:title" content="Chapter 8 Generalized linear mixed-effects models | Learning Statistical Models Through Simulation in R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://psyteachr.github.io/stat-models-v1/generalized-linear-mixed-effects-models.html">
<meta property="og:image" content="https://psyteachr.github.io/stat-models-v1/images/logos/logo.png">
<meta property="og:description" content="This chapter is under construction as of October 14, 2021; contents may change!  8.1 Learning objectives distinguish discrete from continuous data estimate logit models  8.2 Discrete versus...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 8 Generalized linear mixed-effects models | Learning Statistical Models Through Simulation in R">
<meta name="twitter:description" content="This chapter is under construction as of October 14, 2021; contents may change!  8.1 Learning objectives distinguish discrete from continuous data estimate logit models  8.2 Discrete versus...">
<meta name="twitter:image" content="https://psyteachr.github.io/stat-models-v1/images/logos/logo.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.0/transition.js"></script><script src="libs/bs3compat-0.3.0/tabs.js"></script><script src="libs/bs3compat-0.3.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-6NP3MF25W3"></script><script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-6NP3MF25W3');
  </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="include/psyteachr.css">
<link rel="stylesheet" href="include/webex.css">
<link rel="stylesheet" href="include/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Learning Statistical Models Through Simulation in R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Overview</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="correlation-and-regression.html"><span class="header-section-number">2</span> Correlation and regression</a></li>
<li><a class="" href="multiple-regression.html"><span class="header-section-number">3</span> Multiple regression</a></li>
<li><a class="" href="interactions.html"><span class="header-section-number">4</span> Interactions</a></li>
<li><a class="" href="introducing-linear-mixed-effects-models.html"><span class="header-section-number">5</span> Introducing Linear Mixed-Effects Models</a></li>
<li><a class="" href="linear-mixed-effects-models-with-one-random-factor.html"><span class="header-section-number">6</span> Linear mixed-effects models with one random factor</a></li>
<li><a class="" href="linear-mixed-effects-models-with-crossed-random-factors.html"><span class="header-section-number">7</span> Linear mixed-effects models with crossed random factors</a></li>
<li><a class="active" href="generalized-linear-mixed-effects-models.html"><span class="header-section-number">8</span> Generalized linear mixed-effects models</a></li>
<li><a class="" href="modeling-ordinal-data.html"><span class="header-section-number">9</span> Modeling Ordinal Data</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="symbols.html"><span class="header-section-number">A</span> Symbols</a></li>
<li><a class="" href="bibliography.html"><span class="header-section-number">B</span> Bibliography</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/psyteachr/stat-models-v1">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="generalized-linear-mixed-effects-models" class="section level1">
<h1>
<span class="header-section-number">8</span> Generalized linear mixed-effects models<a class="anchor" aria-label="anchor" href="#generalized-linear-mixed-effects-models"><i class="fas fa-link"></i></a>
</h1>
<div class="warning">
<p>This chapter is under construction as of October 14, 2021; contents may change!</p>
</div>
<div id="learning-objectives-2" class="section level2">
<h2>
<span class="header-section-number">8.1</span> Learning objectives<a class="anchor" aria-label="anchor" href="#learning-objectives-2"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>distinguish discrete from continuous data</li>
<li>estimate logit models</li>
</ul>
</div>
<div id="discrete-versus-continuous-data" class="section level2">
<h2>
<span class="header-section-number">8.2</span> Discrete versus continuous data<a class="anchor" aria-label="anchor" href="#discrete-versus-continuous-data"><i class="fas fa-link"></i></a>
</h2>
<p>All of the models we have been considering up to this point have assumed that the response (i.e. dependent) variable we are measuring is <strong>continuous</strong> and numeric. However, there are many cases in psychology where our measurements are of a <strong>discrete</strong> nature. By discrete, we mean that there are gaps between values, such as we would get with Likert scale data. It may also be the case that the values of the response variable reflect categories with no intrinsic ordering. Here are some examples:</p>
<ul>
<li>type of linguistic structure a speaker produces (double object or prepositional object phrase)</li>
<li>which of a set of images a participant is viewing at a given moment</li>
<li>whether the participant has made an accurate or inaccurate selection</li>
<li>whether a job candidate gets hired or not</li>
<li>agreement rating on a Likert scale.</li>
</ul>
<p>Another common type of data is <strong>count</strong> data, where values are also discrete. Often with count data, the number of opportunities for something to occur is not well-defined. Some examples:</p>
<ul>
<li>number of speech errors in a corpus</li>
<li>number of turn shifts between speakers in a conversation</li>
<li>number of visits to the doctor in a given month.</li>
</ul>
<div id="why-not-model-discrete-data-as-continuous" class="section level3">
<h3>
<span class="header-section-number">8.2.1</span> Why not model discrete data as continuous?<a class="anchor" aria-label="anchor" href="#why-not-model-discrete-data-as-continuous"><i class="fas fa-link"></i></a>
</h3>
<p>Discrete data has some properties that generally make it a bad idea to try to analyze it using models intended for continuous data. For instance, if you are interested in the probability of some binary event (a participant's accuracy in a forced-choice task), each measurement will be represented as a 0 or a 1, indicating an inaccurate or an accurate response, respectively. You could calculate the proportion of accurate responses for each participant and analyze that (and many people do) but that is a bad idea for a number of reasons.</p>
<div id="bounded-scale" class="section level4">
<h4>
<span class="header-section-number">8.2.1.1</span> Bounded scale<a class="anchor" aria-label="anchor" href="#bounded-scale"><i class="fas fa-link"></i></a>
</h4>
<p>Discrete data generally has a bounded scale. It may be bounded below (as with count data, where the lower bound is zero) or it may have both an upper and lower bound, such as Likert scale data. or binary data.</p>
</div>
<div id="the-variance-is-proportional-to-the-mean" class="section level4">
<h4>
<span class="header-section-number">8.2.1.2</span> The variance is proportional to the mean<a class="anchor" aria-label="anchor" href="#the-variance-is-proportional-to-the-mean"><i class="fas fa-link"></i></a>
</h4>
<p>In most settings with continuous data, the variance is assumed to be independent of the mean; this is essentially the assumption of homogeneity of variance in a model with a continuous predictor. For discrete data, this assumption of the independence of the mean from the variance is often not met.</p>
<p>We can see this through data simulation. The <code><a href="https://rdrr.io/r/stats/Binomial.html">rbinom()</a></code> function makes it possible to simulate data from a <strong>binomial</strong> distribution, which describes how a collection of discrete observations behaves. Let's consider, for instance, the probability of rain on a given day in Barcelona, Spain, versus Glasgow, U.K. According to <a href="https://www.currentresults.com/Weather/Europe/Cities/precipitation-annual-average.php">this website</a>, Barcelona gets an average of 55 days of rain per year, while Glasgow gets 170. So the probability of rain on a given day in Glasgow can be estimated as 170/365 or about 0.47, where as the probability for Barcelona is 55/365 or about 0.15. Let's simulate 500 years of rainfall for the two cities (assumimg the climate remains constant).</p>
<div class="sourceCode" id="cb234"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rainy_days</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="op">(</span>city <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Barcelona"</span>, <span class="st">"Glasgow"</span><span class="op">)</span>, each <span class="op">=</span> <span class="fl">500</span><span class="op">)</span>,
       days_of_rain <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">500</span>, <span class="fl">365</span>, <span class="fl">55</span><span class="op">/</span><span class="fl">365</span><span class="op">)</span>,
                        <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">500</span>, <span class="fl">365</span>, <span class="fl">170</span><span class="op">/</span><span class="fl">365</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> 

<span class="va">rainy_days</span> <span class="op">%&gt;%</span>
  <span class="fu">ggplot</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span><span class="va">days_of_rain</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_histogram</span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">facet_wrap</span><span class="op">(</span><span class="op">~</span> <span class="va">city</span><span class="op">)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:rbinom"></span>
<img src="08-generalized-linear-models_files/figure-html/rbinom-1.png" alt="**Distribution of number of rainy days for 500 years of simulated rainfall in Barcelona and Glasgow**" width="100%"><p class="caption">
Figure 8.1: <strong>Distribution of number of rainy days for 500 years of simulated rainfall in Barcelona and Glasgow</strong>
</p>
</div>
<p>The distribution for Glasgow is slightly fatter than the distribution for Barcelona. We can also see the greater variability in Glasgow if we look at the standard deviations of these variables.</p>
<div class="sourceCode" id="cb236"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rainy_days</span> <span class="op">%&gt;%</span>
  <span class="fu">group_by</span><span class="op">(</span><span class="va">city</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">summarise</span><span class="op">(</span>sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">days_of_rain</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 2
##   city         sd
##   &lt;chr&gt;     &lt;dbl&gt;
## 1 Barcelona  6.72
## 2 Glasgow    9.09</code></pre>
</div>
<div id="spurious-interactions-due-to-scaling-effects" class="section level4">
<h4>
<span class="header-section-number">8.2.1.3</span> Spurious interactions due to scaling effects<a class="anchor" aria-label="anchor" href="#spurious-interactions-due-to-scaling-effects"><i class="fas fa-link"></i></a>
</h4>
<p>Another reason why treating discrete data as continuous can be problematic is the bounded nature of many discrete scales, which can lead to the detection of spurious interaction effects. For instance, consider the effect of some experimental intervention that increases accuracy. If participants are already highly accurate (e.g., more than 90%) in condition A than in condition B (say, 50%) then the size of the possible effect in A is smaller than the size of the possible effect in B, since accuracy cannot exceed 100%. Thus, it is difficult to know whether any interaction effect reflects something theoretically meaningful, or just an artifact of the bounded nature of the scale.</p>
</div>
</div>
</div>
<div id="generalized-linear-models" class="section level2">
<h2>
<span class="header-section-number">8.3</span> Generalized Linear Models<a class="anchor" aria-label="anchor" href="#generalized-linear-models"><i class="fas fa-link"></i></a>
</h2>
<p>The basic idea behind Generalized Linear Models (not to be confused with General Linear Models) is to specify a <strong>link function</strong> that transforms the response space into a modeling space where we can perform our usual linear regression, and to capture the dependence of the variance on the mean through a <strong>variance function</strong>. The parameters of the model will be expressed on the scale of the modeling space, but we can always transform it back into our original response space using the <strong>inverse link function</strong>.</p>
<p>There are a large variety of different kinds of generalized linear models you can fit to different types of data. The ones most commonly used in psychology are <strong>logistic regression</strong> and <strong>Poisson regression</strong>, the former being used for binary data (Bernoulli trials) and the latter being used for count data, where the number of trials is not well-defined. We will be focusing on logistic regression.</p>
</div>
<div id="logistic-regression" class="section level2">
<h2>
<span class="header-section-number">8.4</span> Logistic regression<a class="anchor" aria-label="anchor" href="#logistic-regression"><i class="fas fa-link"></i></a>
</h2>
<div id="terminology" class="section level3">
<h3>
<span class="header-section-number">8.4.1</span> Terminology<a class="anchor" aria-label="anchor" href="#terminology"><i class="fas fa-link"></i></a>
</h3>
<div class="inline-table"><table class="table table-sm">
<thead><tr>
<th style="text-align:left;">
Term
</th>
<th style="text-align:left;">
Definition
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
<strong>Bernoulli trial</strong>
</td>
<td style="text-align:left;">
An event with a binary outcome, with one outcome considered 'success'
</td>
</tr>
<tr>
<td style="text-align:left;">
<strong>proportion</strong>
</td>
<td style="text-align:left;">
The ratio of successes to the total number of Bernoulli trials
</td>
</tr>
<tr>
<td style="text-align:left;">
<strong>odds</strong>
</td>
<td style="text-align:left;">
The ratio of successes to failures
</td>
</tr>
<tr>
<td style="text-align:left;">
<strong>log odds</strong>
</td>
<td style="text-align:left;">
The (natural) log of the odds
</td>
</tr>
</tbody>
</table></div>
<p>In logistic regression, we are modeling the relationship between the response and a set of predictors in log odds space.</p>
<p>Logistic regression is used when the individual outcomes are Bernoulli trials---events with binary outcomes. Typically one of the two outcomes is referred to as 'success' and is coded as a 1; the other is referred to as 'failure' and is coded as 0. Note that the terms 'success' and 'failure' are completely arbitrary, and should not be taken to imply that the more desireable category should always be coded as 1. For instance, when flipping a coin we could equivalently choose 'heads' as success and 'tails' as failure or vice-versa.</p>
<p>Often the outcome of a sequence of Bernoulli trials is communicated as a <strong>proportion</strong>---the ratio of successes to the total number of trials. For instance, if we flip a coin 100 times and get 47 heads, we would have a proportion of 47/100 or .47, which would also be our estimate of the probability of the event. For events coded as 1s and 0s, a shortcut way of getting the proportion is to use the <code><a href="https://rdrr.io/r/base/mean.html">mean()</a></code> function.</p>
<p>We can also talk about the odds of success, i.e., that the odds of heads versus tails are one to one, or 1:1. The odds of it raining on a given day in Glasgow would be 170:195; the denominator is the number of days it did not rain (365 - 170 = 195). Expressed as a decimal number, the ratio 170/195 is about 0.87, and is known as the <strong>natural odds</strong>. Natural odds ranges from 0 to <span class="math inline">\(+\inf\)</span>. Given <span class="math inline">\(Y\)</span> successes on <span class="math inline">\(N\)</span> trials, we can represent the natural odds as <span class="math inline">\(\frac{Y}{N - Y}\)</span>. Or, given a probability <span class="math inline">\(p\)</span>, we can represent the odds as <span class="math inline">\(\frac{p}{1-p}\)</span>.</p>
<p>The natural log of the odds, or <strong>logit</strong> is scale on which logistic regression is performed. Recall that the logarithm of some value <span class="math inline">\(Y\)</span> gives the exponent that would yield <span class="math inline">\(Y\)</span> for a given base. For instance, the <span class="math inline">\(log_2\)</span> (log to the base 2) of 16 is 4, because <span class="math inline">\(2^4 = 16\)</span>. In logistic regression, the base that is typically used is <span class="math inline">\(e\)</span> (also known as Euler's number). To get the log odds from odds of, say, Glasgow rainfall, we would use <code><a href="https://rdrr.io/r/base/Log.html">log(170/195)</a></code>, which yields -0.1372011; to get natural odds back from log odds, we would use the inverse, <code><a href="https://rdrr.io/r/base/Log.html">exp(-.137)</a></code>, which returns about 0.872.</p>
</div>
<div id="properties-of-log-odds" class="section level3">
<h3>
<span class="header-section-number">8.4.2</span> Properties of log odds<a class="anchor" aria-label="anchor" href="#properties-of-log-odds"><i class="fas fa-link"></i></a>
</h3>
<p>log odds = <span class="math inline">\(\log \left(\frac{p}{1-p}\right)\)</span></p>
<p>Log odds has some nice properties for linear modeling.</p>
<p>First, it is symmetric around zero, and zero log odds corresponds to maximum uncertainty, i.e., a probability of .5. Positive log odds means that success is more likely than failure (Pr(success) &gt; .5), and negative log odds means that failure is more likely than success (Pr(success) &lt; .5). A log odds of 2 means that success is more likely than failure by the same amount that -2 means that failure is more likely than success. The scale is unbounded; it goes from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(+\infty\)</span>.</p>
</div>
<div id="link-and-variance-functions" class="section level3">
<h3>
<span class="header-section-number">8.4.3</span> Link and variance functions<a class="anchor" aria-label="anchor" href="#link-and-variance-functions"><i class="fas fa-link"></i></a>
</h3>
<p>The link function for logistic regression is:</p>
<p><span class="math display">\[\eta = \log \left(\frac{p}{1-p}\right)\]</span></p>
<p>while the inverse link function is:</p>
<p><span class="math display">\[p = \frac{1}{1 + e^{-\eta}}\]</span></p>
<p>where <span class="math inline">\(e\)</span> is Euler's number. In R, you could type this latter function as <code>1/(1 + exp(-eta))</code>.</p>
<p>The variance function is the variance for the binomial distribution, namely:</p>
<p><span class="math display">\[np(1 - p)\]</span>.</p>
<p>The app below allows you to manipulate the intercept and slope of a line in log odds space and to see the projection of the line back into response space. Note the S-shaped ("sigmoidal") shape of the function in the response shape.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:logit-app"></span>
<iframe src="https://shiny.psy.gla.ac.uk/Dale/logit?showcase=0" width="100%" height="500px" data-external="1">
</iframe>
<p class="caption">
Figure 8.2: <strong>Logistic regression web app</strong> <a href="https://shiny.psy.gla.ac.uk/Dale/logit" class="uri">https://shiny.psy.gla.ac.uk/Dale/logit</a>
</p>
</div>
</div>
<div id="estimating-logistic-regression-models-in-r" class="section level3">
<h3>
<span class="header-section-number">8.4.4</span> Estimating logistic regression models in R<a class="anchor" aria-label="anchor" href="#estimating-logistic-regression-models-in-r"><i class="fas fa-link"></i></a>
</h3>
<p>For single-level data, you use the <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> function. Note that it is much like the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function you are already familiar with. The main difference is that you specify a <code>family</code> argument for the link/variance functions. For logistic regression, you use <code>family = binomial(link = "logit")</code>. The logit link is default for the binomial family with a logit link, so typing <code>family = binomial</code> is sufficient.</p>
<p><code><a href="https://rdrr.io/r/stats/glm.html">glm(DV ~ IV1 + IV2 + ..., data, family = binomial)</a></code></p>
<p>For multi-level data where there are random effects to be modeled, you use the <code>glmer</code> function from <code>lme4</code>:</p>
<p><code><a href="https://rdrr.io/pkg/lme4/man/glmer.html">glmer(DV ~ IV1 + IV2 + ... (1 | subject), data, family = binomial)</a></code></p>

</div>
</div>
</div>
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  if (t = document.getElementById("webex-total_correct")) {
    t.innerHTML =
      document.getElementsByClassName("webex-correct").length + " of " +
      document.getElementsByClassName("webex-solveme").length + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

window.onload = function() {
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }

  update_total_correct();
}

</script><script>
$( document ).ready(function() {
  var cite = ' ';
  var psyteachr = ' <a href="https://psyteachr.github.io/"><img src="images/logos/psyteachr_logo.png" style="height: 31px; color: white;" alt="psyTeachR: Reproducible Research" /></a>';
  var license = ' <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/" target="blank"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png"></a>';

  $("footer div.row div:eq(1) p").html(
    psyteachr + license + cite
  );
});
</script><div class="chapter-nav">
<div class="prev"><a href="linear-mixed-effects-models-with-crossed-random-factors.html"><span class="header-section-number">7</span> Linear mixed-effects models with crossed random factors</a></div>
<div class="next"><a href="modeling-ordinal-data.html"><span class="header-section-number">9</span> Modeling Ordinal Data</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#generalized-linear-mixed-effects-models"><span class="header-section-number">8</span> Generalized linear mixed-effects models</a></li>
<li><a class="nav-link" href="#learning-objectives-2"><span class="header-section-number">8.1</span> Learning objectives</a></li>
<li>
<a class="nav-link" href="#discrete-versus-continuous-data"><span class="header-section-number">8.2</span> Discrete versus continuous data</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#why-not-model-discrete-data-as-continuous"><span class="header-section-number">8.2.1</span> Why not model discrete data as continuous?</a></li></ul>
</li>
<li><a class="nav-link" href="#generalized-linear-models"><span class="header-section-number">8.3</span> Generalized Linear Models</a></li>
<li>
<a class="nav-link" href="#logistic-regression"><span class="header-section-number">8.4</span> Logistic regression</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#terminology"><span class="header-section-number">8.4.1</span> Terminology</a></li>
<li><a class="nav-link" href="#properties-of-log-odds"><span class="header-section-number">8.4.2</span> Properties of log odds</a></li>
<li><a class="nav-link" href="#link-and-variance-functions"><span class="header-section-number">8.4.3</span> Link and variance functions</a></li>
<li><a class="nav-link" href="#estimating-logistic-regression-models-in-r"><span class="header-section-number">8.4.4</span> Estimating logistic regression models in R</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/psyteachr/stat-models-v1/blob/master/08-generalized-linear-models.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/psyteachr/stat-models-v1/edit/master/08-generalized-linear-models.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Learning Statistical Models Through Simulation in R</strong>" was written by Dale J. Barr. It was last built on 2021-10-14.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
